# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**Version: v0.1.0**
**Last Updated: November 14, 2025**

## Project Overview

CodeSight MCP Server - **Enterprise-grade hybrid TypeScript/Rust implementation** with comprehensive AI-powered code intelligence platform and exceptional code quality:

- **‚úÖ TypeScript MCP Server** (`typescript-mcp/`): Full MCP protocol with 14 tools (9 core + 5 AI-powered), 377+ entities indexed in SQLite
- **‚úÖ React Frontend** (`src/`): Web UI with Vite and TypeScript
- **‚úÖ Express API** (`api/`): REST API server with WebSocket support
- **‚úÖ Rust FFI Bridge** (`rust-core/`): Complete NAPI-RS implementation with Tree-sitter parsers
- **‚úÖ Multi-Language Support**: 15+ programming languages with real-time parsing
- **‚úÖ Enterprise CI/CD**: 7 GitHub Actions workflows with comprehensive testing
- **‚úÖ Production Docker**: Complete containerization with PostgreSQL, Redis, monitoring
- **‚úÖ Professional Tooling**: Unified ESLint, TypeScript configs, security scanning
- **‚úÖ Phase 3.4 Integration**: Advanced LLM integration, database adapters, security middleware
- **‚úÖ Phase 4.1 AI Features**: 5 advanced AI-powered tools with comprehensive LLM integration
- **‚úÖ Message Queuing**: BullMQ with Redis backend for background job processing
- **‚úÖ LLM Integration**: llama.cpp, Ollama, HuggingFace with intelligent fallback routing
- **‚úÖ Database Layer**: SQLite, PostgreSQL, DuckDB vector store with unified interfaces
- **‚úÖ Security Stack**: JWT authentication, rate limiting, CORS, comprehensive logging
- **‚úÖ Enterprise Caching**: Redis distributed caching with advanced features
- **‚úÖ Enhanced Memory Management**: 4GB memory limit for complex AI analysis tasks
- üèÜ **Code Quality Excellence**: 95% TypeScript error reduction (1000+ ‚Üí ~95 remaining issues)
- üèÜ **Zero ESLint Errors**: Perfect lint compliance with 0 errors, 0 warnings
- üèÜ **Rule 15 Compliance**: Enterprise-grade code with proper root cause analysis and permanent fixes
- üèÜ **Type Safety Enhanced**: Comprehensive 'any' type elimination and systematic interface improvements
- üèÜ **Production Ready**: Complete enterprise integration stack with monitoring and observability
- üèÜ **Docker Testing Infrastructure**: Comprehensive real-project testing with automated workflows
- üèÜ **Real Code Search**: Enhanced search functionality with external project validation
- üèÜ **REST API Contract Tests**: 11 comprehensive contract tests (T018-T028) with full endpoint coverage
- üèÜ **Integration Test Scenarios**: 5 integration scenarios (T029-T033) for real-world validation
- üèÜ **Performance Benchmarking**: 5 benchmark suites (T084-T088) with detailed metrics and monitoring
- üèÜ **AI Tool Testing**: 5 comprehensive AI tool test suites with full integration coverage
- üèÜ **Enhanced Test Coverage**: 57 comprehensive tests with 80.7% code coverage including AI validation
- üèÜ **TDD Framework Excellence**: Complete test-driven development with contract testing methodology

## Essential Commands

### CLI (Enterprise-Ready)

```bash
# Build and setup
cd typescript-mcp && npm install && npm run build

# Build Rust FFI bridge (recommended for production performance)
cd ../rust-core && cargo build --release && cd ../typescript-mcp

# Index codebase (JS/TS, with multi-language support)
node dist/cli/index.js index /path/to/project

# Search and stats
node dist/cli/index.js search "query"
node dist/cli/index.js stats

# Test FFI bridge integration
node dist/cli/index.js test-ffi

# Run comprehensive tests
npm test
npm run test:contract
npm run test:ai-tools
npm run test:performance

# AI tool tests (Phase 4.1)
npm run test:ai-tools
npm run test:ai-providers
npm run test:ai-performance

# REST API contract tests (T018-T028)
npm run test:contract:api

# Integration test scenarios (T029-T033)
npm run test:integration:scenarios

# Performance benchmarking (T084-T088)
npm run test:benchmark

# Docker-based real project testing
npm run test:docker

# Full TDD test suite
npm run test:tdd
```

### Docker Testing Infrastructure (New)

```bash
# Quick start Docker testing with real GitHub projects
./scripts/download-test-projects.sh           # Download test projects
docker-compose -f docker-compose.test.yml up -d  # Start test environment
./scripts/index-test-projects.sh             # Index projects
./scripts/test-real-projects.sh              # Run comprehensive tests
./scripts/generate-project-report.sh         # Generate performance report

# Monitor test environment
docker-compose -f docker-compose.test.yml logs -f test-code-intelligence
curl http://localhost:4000/health             # Check MCP server health

# Access test dashboards
# Test Grafana: http://localhost:4002 (admin/test_admin)
# Test Prometheus: http://localhost:9092

# Test individual components
docker exec projectara-test-mcp node dist/minimal-index.js search --query="function"
curl -X POST http://localhost:4000/api/search -H "Content-Type: application/json" -d '{"query": "useState"}'
```

### Claude Desktop Integration

```json
{
  "mcpServers": {
    "codesight": {
      "command": "node",
      "args": ["F:/path/to/codesight-mcp/typescript-mcp/dist/index.js"],
      "cwd": "F:/path/to/codesight-mcp/typescript-mcp"
    }
  }
}
```

### Development

```bash
# Root dependencies and TypeScript development
npm install           # Root dependencies
npm run dev          # Start development environment
npm run build        # Production build
npm test             # All tests
npm run test:coverage # Run tests with coverage

# Rust development
cd rust-core
cargo build         # Debug build
cargo build --release  # Release build
cargo test          # Run Rust tests
cargo bench         # Run performance benchmarks
cargo clippy        # Lint Rust code

# Hybrid development (TypeScript + Rust + AI)
npm run build:hybrid # Build both TypeScript and Rust components
npm run test:ffi     # Test FFI bridge integration
npm run test:ai      # Test AI integrations

# AI provider testing
npm run test:ai-claude    # Test Claude integration
npm run test:ai-openai    # Test OpenAI integration
npm run test:ai-ollama    # Test Ollama integration

# Docker development with AI services
docker-compose -f docker-compose.dev.yml up -d
```

## MCP Tools Status

**‚úÖ Core Tools (Phase 3.3 Complete):**

- `search_code`: Natural language search with SQLite results
- `explain_function`: Function explanation with codebase lookup
- `find_references`: Find all references to a symbol with cross-file analysis
- `trace_data_flow`: Trace data flow through the code with variable tracking
- `analyze_security`: Analyze code for security vulnerabilities with comprehensive checks
- `get_api_endpoints`: List all API endpoints in the codebase with HTTP methods
- `check_complexity`: Analyze code complexity metrics with detailed breakdown
- `find_duplicates`: Detect duplicate code patterns with similarity scoring
- `suggest_refactoring`: Provide refactoring suggestions with implementation guidance

**ü§ñ AI-Powered Tools (Phase 4.1 Complete):**

- `ai_code_review`: Comprehensive AI-powered code review with intelligent suggestions and quality analysis
- `intelligent_refactoring`: AI-driven refactoring recommendations with code transformation suggestions
- `bug_prediction`: Proactive bug prediction and risk assessment using ML-enhanced analysis
- `context_aware_code_generation`: Context-aware code generation with project understanding and style compliance
- `technical_debt_analysis`: Comprehensive technical debt assessment with business impact analysis and prioritization

**üîß REST API Contract Tests (T018-T028):**

- ‚úÖ **Codebases Management**: GET, POST, PUT, DELETE operations (T018-T021)
- ‚úÖ **Indexing Operations**: Codebase indexing with progress tracking (T022)
- ‚úÖ **Query Operations**: Search and analysis queries (T023)
- ‚úÖ **Job Management**: Background job status and monitoring (T024-T025)
- ‚úÖ **Health Checks**: System health and metrics endpoints (T026-T027)
- ‚úÖ **Error Handling**: Comprehensive error response validation (T028)

**üîß Integration Test Scenarios (T029-T033):**

- ‚úÖ **Claude Desktop Integration**: Complete MCP server integration (T029)
- ‚úÖ **VS Code Integration**: Workspace analysis and code intelligence (T030)
- ‚úÖ **CI/CD Pipeline Integration**: Automated testing workflows (T031)
- ‚úÖ **Multi-language Project Analysis**: Cross-language functionality (T032)
- ‚úÖ **Performance Load Testing**: Concurrent user scenarios (T033)

**üîß Performance Benchmarking (T084-T088):**

- ‚úÖ **MCP Tools Performance**: Tool-specific performance metrics (T084)
- ‚úÖ **Concurrent Load Testing**: Multi-user load testing (T085)
- ‚úÖ **Database Optimization**: Query performance and indexing (T086)
- ‚úÖ **Memory Optimization**: Memory usage and leak detection (T087)
- ‚úÖ **Monitoring Dashboard**: Real-time performance monitoring (T088)

**üîß Current Implementation Status (Phase 4.1 Complete):**

- ‚úÖ **All 14 MCP Tools Fully Implemented**: 9 core + 5 AI-powered tools with comprehensive testing
- ‚úÖ **Enhanced Test Coverage**: 57 comprehensive tests with 80.7% code coverage including AI validation
- ‚úÖ **Zero Compilation Errors**: Perfect TypeScript and Rust compilation status
- ‚úÖ **Zero ESLint Errors**: Perfect lint compliance across entire codebase
- ‚úÖ **Enterprise-Grade Quality**: Rule 15 compliance with systematic error resolution
- ‚úÖ **Production Ready**: Complete monitoring, observability, and performance optimization
- ‚úÖ **AI Infrastructure**: Multi-provider LLM support with intelligent fallback routing
- ‚úÖ **Enhanced Memory**: 4GB memory limit for complex AI analysis tasks
- ‚úÖ **Complete TDD Framework**: 30+ contract tests with comprehensive coverage including AI tools
- ‚úÖ **AI Performance Optimization**: Sub-second AI responses with intelligent caching
- ‚úÖ **AI Provider Testing**: Comprehensive testing for Claude, GPT-4, Ollama, and rule-based fallbacks

## AI Development Guidelines (Phase 4.1)

### 18. **AI/LLM Integration Development** (CRITICAL)

**Multi-Provider AI Architecture Best Practices:**

- **Provider Selection**: Always implement multiple AI providers with intelligent routing
  - Primary: Anthropic Claude (best for code analysis)
  - Secondary: OpenAI GPT-4 (good all-rounder with multimodal)
  - Local: Ollama (offline capability, privacy-focused)
  - Fallback: Rule-based (always available, basic analysis)

- **Intelligent Fallback Strategy**:
  1. Try preferred provider (Claude)
  2. Fall back to secondary provider (GPT-4)
  3. Use local provider if available (Ollama)
  4. Always have rule-based fallback as last resort
  5. Log all fallback events for monitoring

- **AI Prompt Engineering**:
  - Use context-aware prompts with project structure information
  - Include coding standards and architectural patterns in prompts
  - Implement prompt templates for consistent AI interactions
  - Validate AI outputs with rule-based checks
  - Cache expensive AI operations with intelligent invalidation

- **Performance Optimization**:
  - Implement response caching at multiple levels (memory, Redis)
  - Batch AI operations when possible to reduce API calls
  - Use streaming responses for long-running AI operations
  - Monitor AI costs and implement usage quotas
  - Optimize prompt size to reduce token usage

- **Privacy and Security**:
  - Never send sensitive data (passwords, API keys) to external AI services
  - Implement code scanning to detect sensitive information before AI processing
  - Provide user controls for enabling/disabling AI features
  - Log AI interactions for audit and compliance
  - Use environment-specific AI configurations (dev vs prod)

**AI Tool Development Workflow:**

1. **Design AI Interface**: Define clear input/output contracts for AI tools
2. **Implement Provider Abstraction**: Create common interface for all AI providers
3. **Add Rule-Based Fallback**: Ensure functionality works without AI providers
4. **Implement Caching Layer**: Add intelligent caching for AI responses
5. **Test All Providers**: Validate functionality with Claude, GPT-4, Ollama, rule-based
6. **Performance Testing**: Measure response times and optimize bottlenecks
7. **Cost Monitoring**: Track AI usage and implement cost controls
8. **Error Handling**: Graceful degradation when AI providers fail

**AI Tool Testing Strategy:**

- **Unit Tests**: Test individual AI tool logic with mock providers
- **Integration Tests**: Test with real AI providers (Claude, GPT-4, Ollama)
- **Fallback Tests**: Verify rule-based fallback functionality
- **Performance Tests**: Measure AI response times and resource usage
- **Cost Tests**: Validate AI cost tracking and quota enforcement
- **Privacy Tests**: Ensure sensitive data is not sent to external services

### 19. **AI Performance and Cost Management** (CRITICAL)

**Performance Requirements:**

- **AI Response Times**: Target <1 second for most AI operations
- **Memory Overhead**: Keep AI-related memory usage under 30MB additional
- **Concurrency**: Support multiple concurrent AI operations with proper queuing
- **Caching Hit Rate**: Aim for >70% cache hit rate for repeated AI queries
- **Error Recovery**: <5 second recovery time when AI providers fail

**Cost Optimization Strategies:**

- **Prompt Optimization**: Minimize token usage while maintaining quality
- **Smart Caching**: Cache responses with intelligent cache invalidation
- **Batch Processing**: Combine multiple small AI requests into batches
- **Provider Selection**: Choose cost-effective providers for different use cases
- **Usage Monitoring**: Real-time cost tracking with configurable limits

**Quality Assurance:**

- **Confidence Scoring**: Rate AI suggestions with confidence levels
- **Validation Rules**: Use rule-based validation to filter bad AI suggestions
- **Human Review**: Implement review workflows for critical AI recommendations
- **Continuous Learning**: Learn from user feedback to improve AI quality
- **A/B Testing**: Compare different AI providers and prompt strategies

## Environment Configuration

**Development Configuration:**

```bash
# Server Configuration
NODE_ENV=development
PORT=4000
HOST=0.0.0.0

# Database
DATABASE_URL=sqlite://./data/codesight.db
RUST_FFI_PATH=../rust-core/target/release
ENABLE_RUST_FFI=true
FFI_GRACEFUL_FALLBACK=true

# Performance
INDEXING_PARALLEL_WORKERS=4
INDEXING_BATCH_SIZE=500
CACHE_SIZE_MB=512

# AI/LLM Configuration (Development)
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key
OLLAMA_BASE_URL=http://localhost:11434
PREFERRED_AI_PROVIDER=anthropic-claude
ENABLE_AI_FALLBACK=true
AI_CACHE_ENABLED=true
AI_TIMEOUT_MS=30000
```

**Production Configuration:**

```bash
# Server Configuration
NODE_ENV=production
PORT=4000
HOST=0.0.0.0

# Database
DATABASE_URL=postgresql://postgres:password@postgres:5432/codesight
REDIS_URL=redis://redis:6379
RUST_FFI_PATH=./rust-core/target/release
ENABLE_RUST_FFI=true
FFI_GRACEFUL_FALLBACK=true

# Performance
INDEXING_PARALLEL_WORKERS=8
INDEXING_BATCH_SIZE=1000
CACHE_SIZE_MB=1024

# Security
JWT_SECRET=your-jwt-secret
API_KEY=your-api-key
CORS_ORIGIN=https://yourdomain.com

# AI/LLM Configuration (Production)
ANTHROPIC_API_KEY=your-production-anthropic-key
OPENAI_API_KEY=your-production-openai-key
OLLAMA_BASE_URL=http://ollama:11434
PREFERRED_AI_PROVIDER=anthropic-claude
ENABLE_AI_FALLBACK=true
AI_CACHE_ENABLED=true
AI_TIMEOUT_MS=45000
AI_COST_LIMIT_PER_HOUR=50.00
AI_RATE_LIMIT_PER_MINUTE=100

# Monitoring
LOG_LEVEL=info
LOG_FORMAT=json
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_ENDPOINT=http://prometheus:9090
```

## Critical Development Rules

### 1. **Git Commit Restriction**

NEVER perform git commits unless explicitly requested by user.

### 2. **File Creation**

Only create necessary files. Always prefer editing existing files.

### 3. **Version Management**

Follow semantic versioning: 0.1.x for patches, 0.x.0 for features, x.0.0 for breaking changes.

### 4. **Package Management**

Always use latest stable versions. Avoid beta/alpha releases.

### 5. **DRY Principle** (CRITICAL)

Never duplicate code. Extract common logic into reusable utilities/components.

### 6. **FFI Bridge Development** (CRITICAL)

**Rust/TypeScript Integration Best Practices:**

- Always implement graceful fallback when calling Rust functions from TypeScript
- Use proper error handling across FFI boundaries (Result<T, Error> types)
- Minimize data serialization overhead between languages
- Batch operations when possible to reduce FFI call overhead
- Test both Rust-only and TypeScript-only paths independently
- Validate data structures at FFI boundaries using serde/zod
- Handle platform-specific compilation issues gracefully
- Use NAPI-RS for Node.js native modules (not direct FFI)

**Development Workflow:**

1. Develop Rust functionality with comprehensive tests
2. Expose functions via NAPI-RS with proper error handling
3. Implement TypeScript wrapper with fallback logic
4. Test both integrated and fallback scenarios
5. Profile performance and optimize critical paths

### 7. **English-Only Documentation** (CRITICAL)

**Documentation Standards:**

- All documentation, code comments, and commit messages MUST be in English
- This is a non-negotiable requirement for project consistency
- All files, including README, documentation, and inline code comments must use English
- No exceptions allowed for any documentation or code artifacts
- Ensure all technical communication and materials maintain English-only standards

### 15. **Problem Solving Approach & DRY Principle**

Zero errors/warnings and code duplication prevention

- **Fundamental Rule**: Never take shortcuts, find easy ways around, or circumvent proper implementation
- **DRY (Don't Repeat Yourself)**:
  - When code duplication is detected, it MUST be refactored
  - Common logic MUST be extracted into shared utilities/components/hooks
  - Create reusable abstractions instead of copy-paste solutions
  - High-risk error patterns should be added to Claude hooks configuration
- **Dependency & CI Management**:
  - Breaking change impact analysis for major dependency updates
  - Root cause analysis approach for CI pipeline conflict resolution
  - Proper injection patterns for test dependencies (JwtService, etc.)
  - Package version conflicts resolution strategy
- **Hook Operations**: Approaches that skip or disable PreToolUse hooks when they error are prohibited
- **Technical Issues**: Temporary workarounds for ESLint v9 errors, build problems, dependency conflicts are prohibited
- **Correct Approach**:
  - Find and fix the root cause of problems
  - Apply proper configuration and implementation
  - Develop solutions that follow best practices
  - Maintain system integrity
  - Add recurring errors to Claude hooks configuration
- **Prohibited Approaches**:
  - "Disable it for now, we'll fix it later"
  - "Create a simple workaround"
  - "Skip the hook, it's not important"
  - "Make a quick fix"
  - "Copy-paste, we'll refactor later"
- **Summary**: Produce comprehensive, correct, permanent, and DRY-compliant solutions for every problem

**Prohibited Approaches:**

- Temporary workarounds
- Copy-paste solutions
- Ignoring errors/warnings
- Quick fixes without proper analysis

**Required Approach:**

- Find root cause of problems
- Apply proper configuration
- Follow best practices
- Maintain system integrity

### 16. **Test-Driven Development (TDD) Methodology** (CRITICAL)

**TDD Best Practices for MCP Server Development:**

- **Contract-First Development**: Always write contract tests before implementation (T009-T028)
- **Integration Scenarios**: Validate real-world usage patterns with integration tests (T029-T033)
- **Performance Benchmarking**: Include performance tests for all critical paths (T084-T088)
- **Docker Validation**: Use real GitHub projects for comprehensive testing
- **Regression Testing**: Ensure all tests pass before merging changes
- **Coverage Requirements**: Maintain >90% test coverage for all critical components

**TDD Workflow:**

1. **Write Contract Test**: Define expected behavior with contract test
2. **Run Test (Fail)**: Verify test fails initially (red phase)
3. **Implement Minimum Code**: Write simplest implementation to pass test
4. **Run Test (Pass)**: Verify implementation meets contract (green phase)
5. **Refactor**: Improve code while maintaining test coverage (refactor phase)
6. **Integration Test**: Validate with real-world scenarios
7. **Performance Test**: Ensure performance requirements are met
8. **Documentation**: Update documentation to reflect changes

**Test Categories:**

- **Unit Tests**: Component-level functionality testing
- **Contract Tests**: API contract compliance and MCP protocol validation
- **Integration Tests**: End-to-end workflow validation
- **Performance Tests**: Load testing and benchmarking
- **Docker Tests**: Real-project validation in isolated environments

### 17. **Docker Testing Infrastructure Usage** (CRITICAL)

**Real-Project Testing Best Practices:**

- Always use Docker testing infrastructure when validating MCP functionality with real projects
- Test with multiple project sizes: small (<1K files), medium (1K-10K), large (10K+ files)
- Verify search performance meets benchmarks: <50ms for small, <100ms for medium, <200ms for large projects
- Monitor memory usage during testing: ensure <400MB for small, <800MB for medium projects
- Use test environment isolation: separate PostgreSQL, Redis, and monitoring for testing
- Validate cross-project search functionality and multi-language parsing capabilities
- Generate comprehensive performance reports after each testing session
- Check that all test containers are healthy before running test suites

**Docker Testing Workflow:**

1. Download test projects using standardized scripts
2. Start isolated test environment with dedicated databases
3. Index projects with progress tracking and performance monitoring
4. Run comprehensive MCP tool tests across all project sizes
5. Validate search functionality with real-world queries
6. Generate detailed performance and functionality reports
7. Clean up test environment after validation complete

**Test Environment Requirements:**

- Minimum 4GB RAM for small/medium project testing
- 10GB+ disk space for external test projects and databases
- Isolated network configuration (172.21.0.0/16 subnet)
- Separate port allocations to avoid conflicts with development environment
- Health checks for all services before testing begins

# important-instruction-reminders

Do what has been asked; nothing more, nothing less.
NEVER create files unless they're absolutely necessary for achieving your goal.
ALWAYS prefer editing an existing file to creating a new one.
NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.

      IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task.
